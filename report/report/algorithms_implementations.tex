The testing implementation was developed with high modularity in
mind, since it is meant to be a proof-of-concept implementation and
not a a production grade system. High modularity also makes
development easier and the system more robust against changes, two
very important qualities during this project.

The implementation is written in Python and consists of three main parts:
\begin{description}
  \item[Tracker] Manages the model and performs matching between
    hypotheses and images. Provides the filtering PDF
    $\cprob{I_n}{x_n}$ to the particle filter.
  \item[Database] A database with functions for extracting transition
    hypotheses. Provides the prediction PDF $\cprobnext{x}$ to the
    particle filter.
  \item[Particle Filter] A direct  implementation of the procedure in
    table \ref{alg:pf}.
\end{description}

\section{The state transition database}

\subsection{Data format}
A \emph{state transition} is a pair $\trans$ that denotes we have
observed a system go from state $\tf$ to state $\tt$ in one time step.

Technically, the state transition database is implemented as an SQLite3
database. One transition is represented in the database as a row with
the state parameters of the model before and after the
transition. The database also has support for independent sets of
parameters. For instance, the $x$ positions and velocities of an
object may be independent of the $y$ positions and velocities. In this
case, the database would consist of one table of transitions for the
$x$ part of the state and one table with the $y$ part, and the set of
stored transitions would be the Cartesian product of the two
tables. However, this property is not used in the whisker model since
the state parameters are not known to be independent.

\subsection{Prediction $\cprobnext{x}$}

\begin{table}[h]
  \begin{codebox}
    \Procname{$\proc{DB-Predict} (x_{t-1})$}
    \li $ x_t \gets 0$
    \li $ W \gets 0$
    \li \ForEach $(\tf, \tt) \in \proc{Database}$
    \li \Do
      \li $ w \gets \left(\Lpnorm[p]{\tf - x_t}\right)^{-a}$
      \li $ x_t \gets x_t + w \cdot \tt$
      \li $ W \gets W + w$
    \End
    \li \Return $x_t / W$
  \end{codebox}
  \caption{Pseudocode for the prediction function, with the parameters $a$ and $p$.}
  \label{alg:predict}
\end{table}

The \textsc{Predict} function in table \ref{alg:pf} is implemented as a weighted mean of the
state transitions in the database. The function is stated in table
\ref{alg:predict}. Notice the parameters $a$ and $p$. $p$ is a
positive integer that determines which $\Lp$ space to compute the norm
in. $a$ is a positive number, and determines how fast the weight $w$
declines with the distance $\Lpnorm[p]{\tf - x_{t-1}}$. A high $a$
means closer transitions get a much higher weight than ones far away,
see figure \ref{fig:x-to-the-minus-a}.

\begin{figure}
  \centering
  \includegraphics[width=0.4\textwidth,trim=65mm 65mm 65mm 65mm]{x-to-the-minus-a.pdf}
  \caption{$x^{-a}$ versus $x$.}
  \label{fig:x-to-the-minus-a}
\end{figure}




\section{The particle filter}
<<<<<<< HEAD
    A plug-n-play algorithm which only lacks the problem-domain<ref:encyc> specific parts:$x_0$, $\cprob{x_t}{x_{t-1}}$ and $\cprob{I_t}{x_t}$
    \subsection{Initilization $x_0$}
        The particle filter only does tracking thus we need to have an initial guess for $t=0$ which in our case will be hand labeled foreach whisker.
   ======

Since the algorithm only does tracking, we also need to initialize the algorithm with a start guess $x_0$. 
Using this we take a number of samples $X_0 \sim \ndist{x_0}{\Sigma}$ and let the set $X_0$ be an approximation 
of $\prob{Z_0}$. However, the problem of automatic initialization is a difficult one\cite{Hedvig}, and is not covered in this thesis. 
In the testing implementation, knowledge of the start state $Z_0$ is assumed, meaning $x_0 := Z_0$ and $\Sigma := 0$.
=====
    
    \subsection{Goodness $\kappa\cprob{x_t}{I_t}$}
        It also needs an direction to know how good the hypothesis $x_t$ matches the given image $I_t$.
=======
>>>>>>> 11efaf5c91c56de4e73d13fa64d29ac4ce0efbfc

The particle filter implementation is a direct implementation of the
procedure in table \ref{alg:pf}. It is implemented as a function that
takes the parameters $X_{t-1}$, $I_t$, \texttt{importance\_function} and
\texttt{sampling\_function}. The parameters are the hypotheses from
the last time step, the current video frame and the functions to use
as \textsc{Predict} and \textsc{Importance} in \ref{alg:pf},
respectively. This means that the particle filter function is general
and independent of the model used.

\subsection{Initilization $x_0$}
The test implementation needs to be manually initialized. When
tracking generated whiskers, the states were always known and program
could therefore be programmatically inserted. When testing on real
whiskers, the start states were calculated by manually
selecting pixels along each whisker and using a MATLAB script to find
the least squares solution for the coefficients $\langle a_1, a_2, a_3 \rangle$.

\subsection{Prediction $\cprobnext{x}$}


\subsection{Goodness $\kappa\cprob{x_t}{I_t}$}
It also needs an direction to know how good the hypothesis $x_t$ matches the given image $I_t$.

TODO <ref:theorem>

...



\section{Real data}
    \subsection{Pre-processing}

    We want to find the function $\prob{I=\text{whisker}}\in\IS$

    >We want to have a measure on how probable it is for a pixel to hosehould a whisker





