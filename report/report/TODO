
Classify our algorithm (lazy/eager) see bik12

rename goodness to "closeness" since its more widely used in ML

Minkowski metric - L_p norm (L_1(more resistant to noise) and L_inf(noisy))
Our distance functions must be metric, prove this for all.

Feature selection: (100D noise,1D disc. information) - with unweighted euclidian distance the 100D will always dominate \sum(x_i-mu_i)^2
solution: We want large variation in the class labels to be more significant (for example, PCA assumes label variation is proportional to variation, which is some times generally true)

test different combinations of algorithms fitnesses=lambda (func1,func2,...) :[(func1,func2,..),fitness(func1,func2,...)], prod(FuncSpace1,FuncSpace2,...)
best = max(fitnesses)
where fitness is how well the algorithm performes on validatiot-data

try the methods for kNN speedup in our wdb
bucketing
KD-tree

bayes optimal as in bik12, is this applicable ?

==========================================
PF vs condensation

===================== PF as searchblablabla =================

PF is simply a directed search

Searching in this m-dimensional featurespace can be done in O(log(n^m))=O(mlog(n)) but filling it adequately still requires O(n^m)

Considering configurations of the model that are improbable is totally unnecessary<image of whale and flower>


============= Problems ========================

Artifacts from encoding the video.



bik12-holistic appearance-based descriptor


"partikelfiltrering: approximativ slutledning i dynamiska bayesianska nätverk"
Point out the connection between physical kinematic system (present the main formulaes that governs the motions of objects and show that they are infact a dynamic system, then adding uncertaintis we get bayesian network)

Borrow the word reduce from complexity theory and use it as: reducing the problem to an innerstate of an dynamicsystem

Feature extraction vs. feature selection (bik)

IMPORTANT
Just like the up-transformation in SVMs we get a higher probability for seperation for different objects if we (try) transform the 2D image object into our higher dimensinoal model. 

========================================

One problem is that defining a measure on what could be a good fit and the fact on what is really the "ground truth"

=============== WRAPUP ===================

Having the goal to make it an standalone application had some challanges 
compared to do a simple muckup in MATLAB(R) or such since some builtin
functionallity is missing and also having problems like missaligned buffers 
or having to write an adapter between images and matrices as an example.

==========================================
Do an exhausted search for something low dimensional like the snot and then plot all the datapoints over time for a sequence in the video.
Will be very high dimensional so perhaps some projection will be good but keep time as an axis
The goal is to see the "worm" lingering tru the timeline (is it possible to do an variant of density-based clustering of this data to first find the path tru time of these worms given an head of the worm (a startpoint at t_0) and then "tracking" the timeworm? and ofcourse trying to find E[] of the timeworm)

================Analysis====================
can one just do analysis with a cost function, like cost=compution and to maximize accuracy/computations by using an directed search, even so much that we basically lowers the complexity of the algorithm
Is it possible to do somewhat of of complexity analysis of this?
Worstcase data? better data (assumptions in realdata?)

==========================================
Bra grejer att referera till i encylopdian:
>Accuracy, "refers to a measure of the degree to which the predictions of a model match the reality being modeled.
>Passive learning (@Active Learning), where the learner is simply presentedwith a training set over which it has no control.
>Statiscical Active Learning (under active learning), can our thing classify as this perhaps?
tex. "Structure of learning system"-dyker upp som delkapitel, ska vi ha samma struktur som i encyclopedian ?
"Learning system" (which part are the learnigsystem in our case?)
"Winner-Take-All"
>Algorithm Evalation (follow the model when evaluating our algorithm)
>Attribute (synonymsd: <<feature>>,property,trait,characteristic)
>Bake-Off, "Bake-off is a disparaging term for experimental eval-
uation of multiple learning algorithms by a process of
applying each algorithm to a limited set of benchmark
problems." (crossreference:algorithm evalution)
>Bayes Rule
>Bias
>Confusion matrix (realclass vs assigned class) just relate it to if it fails and add risk (indicator if the algorithm starts to slip in the tracking)
>Cost Function (do we apply it somewhere?), can one just do analysis with a cost function, like cost=compution and to maximize accuracy/computations by using an directed search.
>Covariance
>Cross-Validation (is this possible to implement, instead of doing the trivial test/train?)
diagram at p116 (C.pdf) "system dimension" classify the algorithm diagram
>>Curse of Dimensionality   
>Data preperation (data preprocessing)
>Data set (for example we have 2 data sets, a training set which is the input for the learning system for it to analyze and learn a model and a test set which is used to evaluate the model learned by the system.
>>Density Estimation "given a set of observations, which is a random sample from a probability desntiy function f_X(x) desnity estimation attempts to approximate f by fhat, a simple method ..." (also see crossreference)
>Discretization (be carefull with the use of this in the report) [[Interesting enlisting: eager/lazy global/local etcetc]]
>Distance measure (simliarity measure)
>(Exploration, searching in search space)
>Expected Maximization
>Epsilon cover (all points e-close to a subset)
>Error rate
>Error Squared "Error squared is a common loss function used with
regression. This is the square of the difference between
the predicted and true values."
>Evaluation / Evaluation data
>("Expectation propagation is an algorithm for Bayesian
=machine learning (see Bayesian Methods). It tunes the parameters of a simpler approximate distribution (e.g., a Gaussian) to match the exact posterior distribution of the model parameters given the data. ") (readmore) (In kalman (and variants) vs. partikelfilter where you dont need to know the distribution)
>Expacted maximization
>Explanation-Based Learning. Figure . Conventional learner
>Experience curce(learning curves in machine learning)
>Feature extraction/selection (dimensionality reduction basically) (compare clean selection with the probability selection, that is proportional to how important it is, the feature isnt really important to search in if you already can predict it with great certainty)
>Gaussian distribution (good to have as reference and why this is motivated etc.)
>Gaussian process (reference to the kalman filter) (vs dirichlet process)
>Generalization bounds/Error bounds (can we do some analysis on this?, can we predict the performance analytically?)
>Graphical models (use the same terms used here when doing statistics)
>Greedy search, a pretrained PF performes a gready search overtime? (the algorithm assumes the last choose was an correct one right? without looking back "it chooses the best one and moves on without looking back")
>>Hidden markov models (PFs little sister) aspecially (Figure1)
>>Holdout evaluation (test/training set relations, readmore about it good to have in the report) (the opposit is called In-Sample evaluation "this provides a biased estimate of the learning performance" )
>Hypothesis Language (not the particular term but things in it for example) "Most machine learning algorithms can be seen as a procedure for deriving onre or more hypotheses from a set of observations."
>>Hypothesis Space (actually have 2 entries read both)
>>Instance
>>Medoid (instead of just using mean, this will be better against outliners)
>>Kernels (in the context of gaussian process)
>L1-distance (crossref:manhattan distance)
>>Label/Labeled data
>>Lazy learner (PF is the opposite, eager learner)
>Learning as search (is it directly applicable?)
>>Learning curves (great figure)
>>m-estimator (see wikipedia or <Rule learning>)
>>Markov chain monte carlo vs PF? any simalarities?
>>Mean square error "is a model evalutation metric often used with regression models"
>>Measurement scales (categoral vs numeric) and some problems that comes with it.
>>Mixturemodel \sum w_iP(x|D_i) where D_j is different PDFs, kinda like discrete transforms DTF but for ditributions
>>>Model evaluation (do our analysis by this) and do <model selection>, NOTE do we have a mixup with the word model here, what exactly is a model, is our model the same thing?
>Model space (hypothesis space)

=============================================
Basically PF just guides the search and thereby making the algorithm much more effective computionally (effective=acc/compution) and becomes more local and therefore finding the closest match


>Overfitting? could it exist in our case ? theory vs practice
>Cross validation and setting the size of the folds(leave on out cross validation and leave one out error)
>>Regression, is the database part in PF a form ov regression?
>Our case is a special case of PF, since we don't have any control over the subject at all.


"All instances of the test set", nice frase

>>Find common acronyms for all the algorithms and such (MCMC,PF,)


================================================
!!NOTE!!
Model vs Hypotesis (in our case):
hypotesis \in model
that is an hypotesis is just given parameters on the model
what then is the model evaluation as described in the encyclopedia in our case?
================================================

=============== RANDOM ===================

+, having signature R->R

==Lookup words from above(are these relevant?)==
>Hypotesis Language (under ANN.crossreference)
>Semi supervised learning (Co-training)
>Gaussian processes
>Similarity measure
>ROC analysis
>Learning Curves in Machine learning
>Leave-on-out error (interesting)
>>Naive bayes, do we use these assumptions in PF?
>Supervised learning
>Could one apply reinforcement learning somehow taking "the future" decision into consideration, that is if i choose this as most.prob solution at t what whould that give me in t+1,t+2,.. (basically heightens the total expected result, that is the result for the entire video, and since we dont run this in realtime we can use these types of expensive algorthims. (check it out further before going in to it more)

===================================================================
Its work a bit in the same way as feature selection the more uncertain you are if a feature parameter is correct the more you spread the search there
(Is it possible for the algorithm to sense when you are unceratain of the value for some parameter and lay extra effort until you have it ?) an example would be if one could dynamically choose the number of particles needed depending on how sure you are about the result (after all this isnt a realtime application)

===========================================
According to "Att genomföra projektarbeten"

