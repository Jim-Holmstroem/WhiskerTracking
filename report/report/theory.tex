\subsection{Introduction}
The core of the tracking engine used is a technique known as the \emph{particle filter}. The particle filter is a kind of Bayesian filtering where one uses discrete hypotheses, also known as \emph{particles}, to approximate continuous probability distributions \cite{ProbRob}. It builds upon the theory of \emph{Markov Processes} and the \emph{Hidden Markov Model}.

\subsection{Markov processes and the Hidden Markov Model}
A Markov process is a special case of a stochastic process. For a Markov process, the next state depends only on the present state and not on past states. For this reason, a Markov process is often said to be ``forgetful''.

In mathematical terms, a Markov process satisfies the following:
\begin{equation}
 p\left(Z_t|Z_{t-1} \wedge Z_{t-2} \wedge \dots \wedge Z_0\right) = p\left(Z_t|Z_{t-1}\right),
\end{equation}
where $Z_t$ is the system's \emph{state} at time $t$ and $p\left(Z_t|Z_{t-1} \wedge Z_{t-2} \wedge \dots \wedge Z_0\right)$ is the probability that the system will have state $Z_t$ at time $t$, given that the previous states where $Z_{t-1}, Z_{t-2},\dots, Z_0$.


\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{hmm-graph.pdf}
  \caption{Schematic image of a Hidden Markov Model.}
  \label{fig:hmm-graph}
\end{figure}

\subsection{The Hidden Markov Model}

The working principle of the particle filter is based on the \emph{Hidden Markov Model} (HMM). A HMM describes a Markov process where we cannot measure the state $Z_t$ of the system directly - it is ``hidden''\cite{EncyclopediaMachineLearning}. Instead we obtain an \emph{observation} $I$\footnote{In this thesis, the observation is a grayscale \emph{image}, therefore the observation is denoted $I$.}  of the state. This \emph{perception} is generally non-deterministic, so we need to denote it as $p(I_t|Z_t)$ which is the probability that we will observe $I_t$ if the state of the system is $Z_t$.

\subsection{The Particle Filter}

One way to compute the state $Z_t$ would be to perform an exhaustive search in the state space, and select the state for which $\cprob{I_t}{Z_t}$ is maximised. However, as the number of parameter grows, the state space can get very large. If the state is defined by $n$ independent parameters, the volume of the state space grows exponentially with $n$.

The particle filter is a kind of Bayesian filtering where one uses discrete hypotheses to approximate the probabilities $\cprobnext{Z}$.


The Particle Filter is a technique for tracking a process described by a HMM. It uses a finite set $X_t$ of hypotheses to approximate the probability function $\cprobnext{Z}$. The hypotheses $X_t$ are also known as \emph{particles}, thereby the term ``particle filter''.

\begin{figure}
  \centering
  \includegraphics[width=0.8\textwidth]{hmm-pf-graph/hmm-graph.pdf}
  \caption{Schematic image of the Particle Filter working alongside a Hidden Markov Model.}
  \label{fig:hmm-graph}
\end{figure}

Figure \ref{fig:hmm-graph} shows the working principle of the Particle Filter working alongside a Hidden Markov Model. The following is the core function of the Particle Filter:

\begin{quote}
  \emph{The particle filter attempts to approximate the probability density function $\cprobnext{Z}$ as a set $X_t$ of discrete hypotheses.}
\end{quote}

More particles mean greater accuracy, since the PDF can then be approximated more closely. However, using many particles is also computationally expensive. Therefore the number of particles is an important quantity. The Particle Filter employs a few tricks to \emph{filter} the hypotheses, keeping probable ones and throwing improbable ones away, in order to reduce the number of particles needed for a good approximation. The filter works in four steps:

\begin{description}
%\item[Initialization:] Since the algorithm only does tracking, we need to initialize the algorithm with a start guess $x_0$. Using this we take a number of samples $X_0 \sim \ndist{x_0}{\Sigma}$ and let the set $X_0$ be an approximation of $\prob{Z_0}$. \footnote{The problem of initialization is a difficult one\cite{Hedvig}, and is not covered in this project. $\Sigma = 0$ was used in the testing implementation.}

\item[Prediction] The hypotheses $X_t$ are updated in the \emph{prediction} step to an approximation of $\cprobnext{Z}$. This is done by drawing new samples $\bar{X}_t \sim \cprobnext{X}$.
\item[Perception] By measuring the state of the system, we gain an \emph{observation} $I_t \sim \cprob{I_t}{Z_t}$ of the state $Z_t$.
\item[Filtering] The observation $I_t$ of the system is then used for filtering bad hypotheses out of $\bar{X}_t$. We draw samples $X_t$ from $\bar{X}_t$ with probabilities given by $\cprob{I_t}{\bar{X}_t}$. As a result, $X_t$ will be a subset of $\bar{X}_t$ where more probable hypotheses appear multiple times. For this reason, this is also known as the \emph{resampling} step. The set $X_t$ is the \emph{belief}, our approximation of $\cprobnext{Z}$.
\item[Selection] Finally, we produce a single hypothesis $x_t$ from $X_t$ as our \emph{estimate} of the state $Z_t$. Supposing $X_t$ is a good approximation of $\cprobnext{Z}$, and that $\cprobnext{Z}$ is unimodal, the mean value of $X_t$ is a good estimate since it approximates the expectation of $\cprobnext{Z}$. If $\cprobnext{Z}$ is multimodal, however, the mean could be a bad estimate since it may be in a region of very low probability even if $X_t$ is a good approximation of $\cprobnext{Z}$.
\end{description}

\subsubsection{The Particle Filter algorithm}
\begin{codebox}
\Procname{$\proc{Particle-Filter} (X_{t-1},I_t)$}
\li $\bar{X}_t \gets \emptyset$
\li \ForEach $x_{t-1}^i \in X_{t-1}$
\li \Do
  \li $x_t^i \gets \proc{Predict}(x_{t-1}^i)$
  \li $w^i \gets \proc{Importance}(x_t^i,I_t)$
  \li Add $\left<x_t^i, w^i\right>$ to $\bar{X}_t$
\End
\li

\li $X_t \gets \emptyset$

\li \While $\abs{X_t} < \abs{\bar{X}_t}$
\li \Do
  \li Take $\left<x_t^i, w^i\right>$ from $\bar{X}_t$ with probability $\propto w^i$, with replacement
  \li Add $x_t^i$ to $X_t$
\End
\li \Return $X_t$
\end{codebox}



We draw a set $\bar{X}_t = \xtmN{x}{t}{i}{N}$ of samples from $p$. These samples roughly represent a probability distribution for the current state $x_t$, but we have yet to consider our observation. Therefore, we will create a new probability distribution weighted by how probable the observation $z_t$ is. For each $x_t^m$, we let $w_t^m := q\left(z_t | x_t\right)$. This defines a discrete probability distribution where $x_t^m$ is assumed with a probability proportional to $w_t^m$. From this final distribution we again draw $N$ samples $X_t$, which will be our estimate of the current state. The elements $x_t^m$ are referred to as \emph{particles} and the set $X_t$ as the \emph{belief at time $t$}.

In this thesis, $x_{t-1}$ is not known. Rather $x_{t-1}$ is estimated with a set $X_{t-1}$ of $N$ particles. In this case, $x_t^m$ is sampled with probability $p\left(x_t^m | x_{t-1}^m\right)$.



\subsubsection{Curse of dimensonality}


% """
%The "Curse of dimensionality", is a term coined by Bellman to describe the
%problem caused by the exponential increase in volume associated with adding
%extra dimensions to a (mathematical) space. One implication of the curse of
%dimensionality is that some methods for numerical solution of the Bellman
%equation require vastly more computer time when there are more state variables
%in the value function.

%For example, 100 evenly-spaced sample points suffice to sample a unit interval
%with no more than 0.01 distance between points; an equivalent sampling of a
%10-dimensional unit hypercube with a lattice with a spacing of 0.01 between
%adjacent points would require 1020 sample points: thus, in some sense, the
%10-dimensional hypercube can be said to be a factor of 1018 "larger" than the
%unit interval. (Adapted from an example by R. E. Bellman, see below.)
% """

from:
"R. Bellman, Adaptive control Processes, p.94, Princeton University Press, NJ,
1961."

“In view of all that we have said in the foregoing
sections, the many obstacles we appear to have
surmounted. What casts the pall over our victory
celebration? It is the curse of dimensionality, a
malediction that has plagued the scientist from
earliest days.”


show curse of dimensionallity with a simple like in bik12.lecture7
1D->2D
either maintain density samples increases drastically
or maintain samples and density decreases drastically
2D->3D
even worse

To have a sample density of C we need $\Ordo{C^n}$ samples for n-dimensional data,
that is the number of samples grows exponential on the number of dimensions.
And a consequence of this is that in order to approximate some
function defined in higher dimensional space one needs many more samples.

One more thing with the high dimensional space is the large boundaries 
of the sample-set then from lower dimensional space which results in orders of
magnitude higher chance for an point one want to approximate to fall outside
the sample-set and needs to be extrapolated instead of interpolate which is
much better.

% """
%
% Number of states grows exponentially in n (assuming fixed number of
% discretization levels per coordinate)
%
% """

%
%"""
% One solution on how to make the effects of the curse of dimensionality is to
% make a directed search..
%"""
%

%
%"""
% Bellmans dynamic programming (DP) requires knowledge of transition
% probablities of the dynamic system from ones state to the next
%"""
%




The 8 DOF in our model produces vast amounts of space in our feature space and this has the consequence that we need proportional to $n^8$ datapoints to fill it to an specified density c.

For instance, we would need $4^8=65536$ samples just to make a grid with 4 samples in each DOF which in many cases (aspecially for hand labeled data). 

This phenomen of having hue searchspace in highdimensinonal space is fairly common and have the name "Curse of dimensionality".

One way to somewhat overcome this emptyness in space is to have a dynamic (active?) algorithm that adopts the sample density 
according to the models relative frequency in that area and this results in, for a given amount of samples, its more likely 
for an sampled model to occure in a more densly pre-sampled (pre-sampled?) area, in fact this method when doing it right (ideally) 
gives: given a set of samples the overall density for all the samples in the sampledatabase would be optimal) [proof for this will be given in <blabla>]
... (use the world hypotesis instead of sample, or perhaps sampled-hypotesis)
(below is perhaps somewhat redudant, but one can pick bits and pieces from both)
So having a bias towards trying out more plausible hypotesis for the models innerstate is better than 
doing a naive exhausted search tru the entire feature space, this could only be used if you have $\le$ 3 DOF as in for example finding straight edges with houghtransformation[ref].
...
One method that uses prior knowledge of the models PDF and a pretrained database containing knowledge on how to approximate the models PDF in the next timestep is particle filter which is an (instance?) of the ideal bayesian filter.



===================

\begin{definition}
    The render function $R$ takes an hypotesis $x$ and renders an image with an
    reassemblance on how a real whisker would have looked like having the same
    underlying model and parameters as $x$.
    \begin{equation}
        \begin{split}
            R : \HS &\rightarrow \IS\\
                x &\mapsto render(x)
        \end{split}
    \end{equation}
\end{definition}


\subsection{Sensory Cues}

The biggest problem with computer vision is that computers do not have
vision, but only a data input device in the form of a camera. 

<ref to machine vs biological comparison study>


\begin{definition}
    %%TODO cue function/transformation (cue says more doesnt it?) change all
    %%use
    The cue function $\phi_{cue}$ takes an image $I$ and renders(depicts?) one property of the
    image like intensity, edges or ridges.
    \begin{equation}
        \begin{split}
            \phi_{cue} : \IS &\rightarrow \IS\\
                I &\mapsto cue(I)
        \end{split}
    \end{equation}
    If the cue function for any cue is under consideration we simply denote that with $\phi$.
\end{definition}


<image showing the use of $\phi$>


\subsection{Particle filtering whisker movements}
Here we propose a way to model whiskers as a dynamic system.

\subsection{Kinematic whisker models}

In all our models we have separated the head from the whiskers since they have
such different kinematic properties and actually are attached to each other.


\input{model.tex}

The equation of elastic line ... [Grundläggande Hållfasthetslära - Hans Lundh
p94 (7.6)]

The force that comes from the head moving on the base of the whisker is just 
sucked up by the Boundaryvalues and it will still be valid assumptions for the
elasticline to hold.

Under just a few assumptions that the material is linear elastic and the
deformations are small we have the ...



\begin{theorem} %TODO svagare?
    \label{thm:response_max}
    Let $f$ be a positive Riemann function with compact support, then
    \begin{equation}
        \argmax{\bar{e}}
            \left(
            \sum\limits_{\Omega}{f(\bar{x})f(\bar{x}-\bar{e})}
            \right)
            =0
    \end{equation}
\end{theorem}
\begin{proof}
    Firstly define the window function as
    \begin{equation}
        W_a^b(x)=
        \begin{cases}
            0,~& x<a\\
            1,~& a=<x=<b\\
            0,~& x>b
        \end{cases}
    \end{equation}
    Multiplication
    \begin{equation}
        (W_a^bW_c^d)(x)=W_{\max(a,c)}^{\min(b,d)}(x)
    \end{equation}
    Translation
    \begin{equation}
        W_a^b(x-e)=W_{a+e}^{b+e}(x)
    \end{equation}
    Integration
    \begin{equation}
        \label{eq:int_window}
        \sum{W_a^b(x)dx}=\Theta(b-a)
    \end{equation}

    \begin{equation}
        \begin{array}{c}
            
            \argmax{e}\left(
                \sum
                    {
                        W_a^b(x)W_a^b(x-e)
                    }
                \right)
                =\\
            \argmax{e}\left(
                    \sum
                        {
                            W_a^b(x)W_
                                {
                                    a+e
                                }
                                ^
                                {
                                    b+e
                                }
                                (x)
                        }
                \right)
                =\\
            \argmax{e}\left(
                    \sum
                        {
                            W_
                                {
                                    \max(a,a+e)
                                }^
                                {
                                    \min(b,b+e)
                                }
                                (x)
                        }
                 \right)
                =\\
            \argmax{e}\left(
                    \Theta(\min(b,b+e)-\max(a,a+e))
                 \right)
                =\\
            %\left\{\text{
            %        max the min and min the max at the same time
            %        }
            %    \right\}=\\
            0
        \end{array}
      \end{equation}

    This trivially holds with superposition of windows, since all windows will scale and translate the same way. 
    With a finite support $e=0$ is the only solution. Additionaly this also hold in higher finite dimensions since we can just repeat the process for one dimension at a time.
    
    All riemann functions can be written as a superposition of windows like this
    \begin{equation}
        f(x)=\sum{c_iW_{a_i}^{b_i}(x)}
    \end{equation}

    $\therefore$ Each riemann function $f$ with finite support will have a $e=0\qed$

\end{proof}

=============================

\subsubsection{ Theoretical evalutaion (formal methods)}

============================

============== MODELS =================

One possible model is to borrow the model for beam under small 
deformations from the theory of strength of materials,
after all the whisker is a beam but we dont have small 
deformations at all but we assume that the model will approximatly hold ony way.


