\newcommand{\xmtN}[4]{
  \left\{#1_{#2}^{#3}\right\}_{#2=1}^{#4}
}
\newcommand{\interval}[2]{
  \left[#1, #2\right]
}

\subsection{The particle filter}
\subsubsection{Introduction}
The core of our tracking engine is a technique known as the \emph{particle filter}. The particle filter is a kind of Bayesian filtering where one uses discrete hypotheses to approximate continuous probability distributions. The main idea can be outlined as follows. We have a system with a state we cannot directly measure. We have an observation of the current system state, and a number of probable hypotheses of the previous state. From these hypotheses, we create new hypotheses for the current state, then assign weights to each new hypothesis depending on how probable the observation is under that hypothesis. If the observation is probable when the system is in the hypothesised state, then that hypothesis gets a high weight. Finally, we select the most probable hypotheses and let them represent our estimation of the system state. If we have a good model of the system, this method can give a good estimate of the system state.



\subsubsection{Formal description of the particle filter}
Suppose we have a system described by the state $x_t$ at time $t$. $x_t$ can be thought of as a vector of state parameters. We know the previous state $x_{t-1}$ and have an observation $z_t$ of the system at the current time. Our observation $z_t$ suffers from interference, so we cannot directly read the current state $x_t$ from this observation. However, we can estimate $x_t$ if we know the following things about the system:

\begin{itemize}
\item A probability function $p_t$, where $p_t\left(x_t | x_{t-1}\right)$ is the probability that the current state is $x_t$ if the previous state was $x_{t-1}$.
\item A probability function $q_t$, where $q_t\left(z_t | x_t\right)$ is the probability that we observe $z_t$ if the current state is $x_t$.
\end{itemize}

We draw a set $\bar{X}_t = \xmtN{x}{m}{t}{N}$ of samples from $p_t$. These samples roughly represent a probability distribution for the current state $x_t$, but we have yet to consider our observation. Therefore, we will create a new probability distribution weighted by how probable the observation $z_t$ is. For each $x_t^m$, we let $w_t^m := q_t\left(z_t | x_t\right)$. This defines a discrete probability distribution where $x_t^m$ is assumed with a probability proportional to $w_t^m$. From this final distribution we again draw $N$ samples $X_t$, which will be our estimate of the current state. The elements $x_t^m$ are referred to as \emph{particles} and the set $X_t$ as the \emph{belief at time $t$}.

In our case, we do not really know $x_{t-1}$, rather we have an estimate $X_{t-1}$ of $N$ particles. In this case, we sample $x_t^m$ with probability $p_t\left(x_t^m | x_{t-1}^m\right)$.

The particle filter algorithm can be stated as follows:
\begin{enumerate}
\item ParticleFilter($X_{t-1}, z_t$):
\item Let $\bar{X_t} = \emptyset$.
\item For $m:=1$ to $\left|X_{t-1}\right|$:
  \begin{enumerate}
  \item Draw $x_t^m$ with probability $p_t\left(x_t^m | x_{t-1}^m\right)$.
  \item Let $w_t^m := q_t\left(z_t | x_t^m\right)$.
  \item Add $(x_t^m, w_t^m)$ to $\bar{X_t}$.
  \end{enumerate}
\item Let $X_t := \emptyset$.
\item For $m:=1$ to $\left|X_{t-1}\right|$:
  \begin{enumerate}
    \item Draw $x_t^m$ with probability proportional to $w_t^m$
    \item Add $x_t^m$ to $X_t$.
  \end{enumerate}
\item Return $X_t$.
\end{enumerate}

\subsection{Kinematic whisker models}
What are our kinematic models?
